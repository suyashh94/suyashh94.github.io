<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="theme-color" content="#0f1115" />
  <title>World of Bits / MiniWoB (ICML 2017) — Notes</title>
  <link rel="stylesheet" href="../../assets/styles.css" />
  <script src="../../assets/theme.js" defer></script>
</head>
<body>
  <header class="site-header">
    <div class="wrap">
      <div>
        <h1 class="site-title">World of Bits / MiniWoB (ICML 2017)</h1>
        <div class="site-sub">Benchmark for web‑based agents · <a href="../vla_learning_plan.html">← Back to VLA</a></div>
      </div>
      <div class="right">
        <button id="theme-toggle" class="theme-toggle" aria-label="Toggle theme">Light Theme</button>
      </div>
    </div>
  </header>
  <main class="wrap">
    <section class="panel">
      <div class="kicker">Paper Overview</div>
      <h2>World of Bits: An Open‑Domain Platform for Web‑Based Agents (ICML 2017)</h2>
      <p>
        World of Bits (WoB) proposes a realistic testbed for agents that operate computers via the web. Instead of game‑like simulators,
        WoB exposes agents to real websites and miniature web tasks, interacting with low‑level <em>keyboard</em> and <em>mouse</em> events like a human user.
        The goal is to close the “realism gap” in RL by studying perception, language understanding, and action in everyday interfaces.
      </p>
      <p class="meta">
        Paper: <a href="https://proceedings.mlr.press/v70/shi17a.html" target="_blank" rel="noopener">Shi et&nbsp;al., ICML 2017 — PMLR v70</a>
      </p>
    </section>

    <section class="panel">
      <h2>Why it matters</h2>
      <ul>
        <li><strong>Realism over games:</strong> Research on RL agents often uses synthetic environments; WoB targets <em>real websites</em> and practical mini‑tasks that resemble everyday computer use.</li>
        <li><strong>Multimodality:</strong> Agents must parse text (instructions), vision (screens), and structure (forms, buttons) to decide actions.</li>
        <li><strong>Generalization:</strong> Web tasks vary widely; progress here often transfers to broader computer‑use agents.</li>
      </ul>
    </section>

    <section class="panel">
      <h2>What’s in WoB</h2>
      <ul>
        <li><strong>MiniWoB:</strong> A suite of small, controlled web tasks (e.g., click a button, fill a form, drag a slider). These are ideal for rapid iteration and ablations.</li>
        <li><strong>Real‑web tasks:</strong> Crowdsourced tasks on actual websites with natural‑language goals and demonstrations from human workers.</li>
        <li><strong>Low‑level actions:</strong> Agents act via mouse and keyboard events (click, type, focus, submit, scroll), mirroring human interaction.</li>
        <li><strong>Reproducibility:</strong> HTTP caching creates a stable, offline approximation of sites to counter the transience of the web.</li>
        <li><strong>Demonstrations + RL:</strong> Human demos bootstrap learning (behavior cloning), and RL fine‑tunes policies on task rewards.</li>
      </ul>
    </section>

    <section class="panel">
      <h2>Problem setup</h2>
      <ul>
        <li><strong>Input:</strong> An instruction (e.g., “Book a flight on X”), plus visual/structural context from the page.</li>
        <li><strong>Action space:</strong> Low‑level events on DOM elements or coordinates; sequences form full workflows.</li>
        <li><strong>Success signal:</strong> Task‑specific checks (e.g., presence of expected text, page state) define rewards and episode termination.</li>
      </ul>
    </section>

    <section class="panel">
      <h2>Data and reproducibility</h2>
      <ul>
        <li><strong>Crowd‑authored tasks:</strong> Workers define natural‑language tasks and provide demonstrations by completing them.</li>
        <li><strong>Cached web:</strong> HTTP traffic is cached so tasks can be reliably replayed offline for training and evaluation.</li>
      </ul>
    </section>

    <section class="panel">
      <h2>Learning recipes</h2>
      <ul>
        <li><strong>Behavior cloning (BC):</strong> Supervised learning on demo trajectories to initialize a competent policy.</li>
        <li><strong>Reinforcement learning (RL):</strong> Fine‑tune with task rewards once a policy starts to succeed.</li>
      </ul>
      <p class="meta">The original work shows agents trained with BC and RL can complete a range of WoB tasks.</p>
    </section>

    <section class="panel">
      <h2>Limitations and gotchas</h2>
      <ul>
        <li><strong>Fragility to layout changes:</strong> Real websites evolve; cached snapshots help but can drift from production sites.</li>
        <li><strong>State explosion:</strong> The space of interactions is vast; careful action schemas and curriculum help.</li>
        <li><strong>Evaluation:</strong> Success criteria need to be precise to avoid reward hacking.</li>
      </ul>
    </section>

    <section class="panel">
      <h2>Where this led next</h2>
      <ul>
        <li><strong>MiniWoB++</strong> and follow‑ups that standardized tasks and tooling.</li>
        <li><strong>Workflow‑Guided Exploration</strong> (ICLR’18) adding structure‑aware exploration on real sites.</li>
        <li><strong>Mind2Web, OSWorld</strong> and modern agents that operate full browsers/VMs with multimodal models.</li>
      </ul>
    </section>

    <section class="panel">
      <h2>Get started today</h2>
      <ul>
        <li>Prototype on MiniWoB/++ tasks to test observation encodings and action schemas.</li>
        <li>Use behavior cloning on demos, then RL for refinement.</li>
        <li>For real‑site tasks, couple a browser driver (e.g., Playwright/Selenium) with caching/replay to stabilize training.</li>
      </ul>
      <p class="meta">See also the VLA learning plan for downstream datasets and agents.</p>
    </section>
    <section class="panel">
      <h2>Original Notes (verbatim)</h2>
      <pre>Briefing: World of Bits (WoB) - An Open-Domain Platform for Web-Based Agents
Source: Shi, T., Karpathy, A., Fan, L., Hernandez, J. & Liang, P. (2017). World of Bits: An Open-Domain Platform for Web-Based Agents. Proceedings of the 34th International Conference on Machine Learning, in Proceedings of Machine Learning Research 70:3135-3144.

Date: 2017

This briefing outlines the key aspects of "World of Bits" (WoB), an innovative platform designed to advance reinforcement learning (RL) research by enabling agents to perform tasks on the Internet using low-level keyboard and mouse actions.

Main Themes:
Addressing the Realism Gap in Reinforcement Learning: The core motivation behind WoB is to introduce "open-domain realism" into reinforcement learning, a characteristic currently lacking in simulated game environments. The authors argue that while these simulations have "greatly accelerated research," they do not mirror the complexity and variability found in "tasks in computer vision or natural language processing, which operate on artifacts created by humans in natural, organic settings." WoB aims to bridge this gap by offering a platform where agents interact with real-world web environments.
Facilitating Research in Web-Based Reinforcement Learning: WoB is explicitly designed to "foster reinforcement learning research" in a web-based context. This involves enabling agents to perform tasks on the Internet using "low-level keyboard and mouse actions," thereby simulating how a human user would interact with a website.
Key Challenges and Methodologies for Platform Development: The creation of WoB necessitated overcoming two significant challenges:
Curating Diverse and Engaging Tasks: The first challenge was "to curate a large, diverse set of interesting web-based tasks." This was addressed by employing crowdworkers.
Ensuring Reproducibility and Reward Structures: The second, and perhaps more critical, challenge was "to ensure that these tasks have a well-defined reward structure and are reproducible despite the transience of the web." The methodology to achieve this involves:
Crowdworker Task Creation: Crowdworkers "create tasks defined by natural language questions."
Demonstrations for Learning: Crowdworkers also "provide demonstrations of how to answer the question on real websites using keyboard and mouse."
Caching for Reproducibility: To combat the inherent transience of the web, "HTTP traffic is cached to create a reproducible offline approximation of the web site." This ensures that the environment for agent training remains consistent.
Demonstrated Success of Agent Training: The research concludes by showing the viability of the platform. Agents trained using established methods were successful in completing a variety of tasks within WoB. Specifically, the authors state that "agents trained via behavioral cloning and reinforcement learning can successfully complete a range of our web-based tasks."
Most Important Ideas/Facts:
WoB's Purpose: To provide an "open-domain platform for web-based agents" to enhance realism in RL research by operating on the Internet.
Agent Interaction: Agents interact with web environments using "low-level keyboard and mouse actions."
Core Problems Addressed: The lack of open-domain realism in existing RL environments and the transient nature of the web for research reproducibility.
Task Generation Method: Crowdworkers define tasks using natural language and provide demonstrations.
Reproducibility Solution: HTTP traffic caching creates "a reproducible offline approximation of the web site."
Proof of Concept: Agents trained with behavioural cloning and reinforcement learning successfully completed tasks, validating the platform's effectiveness.
In summary, World of Bits offers a crucial step forward for reinforcement learning by providing a realistic, diverse, and reproducible environment for training agents to navigate and interact with the dynamic and complex world of the Internet.</pre>
      <p class="meta">Imported verbatim from notes/wob.txt</p>
    </section>
  </main>
</body>
</html>
